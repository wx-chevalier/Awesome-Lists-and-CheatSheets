# Transformer List

- [2018~The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/): In this post, we will look at The Transformer – a model that uses attention to boost the speed with which these models can be trained.

- [2023~The Transformer Family Version 2.0](https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/): Many new Transformer architecture improvements have been proposed since my last post on “The Transformer Family” about three years ago. Here I did a big refactoring and enrichment of that 2020 post — restructure the hierarchy of sections and improve many sections with more recent papers. Version 2.0 is a superset of the old version, about twice the length.

# Resources

## Courses

- [2022~The Hugging Face Course 🎥](https://github.com/huggingface/course): This repo contains the content that's used to create the Hugging Face course. The course teaches you about applying Transformers to various tasks in natural language processing and beyond. Along the way, you'll learn how to use the Hugging Face ecosystem — 🤗 Transformers, 🤗 Datasets, 🤗 Tokenizers, and 🤗 Accelerate — as well as the Hugging Face Hub. It's completely free and open-source!

## Series

- [2021~基于 Transformers 的自然语言处理(NLP)入门 #Series#](https://datawhalechina.github.io/learn-nlp-with-transformers/#/): Natural Language Processing with transformers. 本项目面向的对象是：NLP 初学者、transformer 初学者，有一定的 python、pytorch 编程基础，对前沿的 transformer 模型感兴趣，了解和知道简单的深度学习模型。
