# Document Representation List

- [2016~NLP Research Lab Part 1: Distributed Representations](http://blog.districtdatalabs.com/nlp-research-lab-part-1-distributed-representations): How I Learned To Stop Worrying And Love Word Embeddings

# Word Vectors

- [2018~Understanding word vectors](https://gist.github.com/aparrish/2f562e3737544cf29aaf1af30362f469): Understanding word vectors: A tutorial for "Reading and Writing Electronic Text," a class I teach at ITP.

# Word2Vec

- [The Code Word2Vec Tutorial Part I: The SkipGram Model](http://mccormickml.com/assets/word2vec/Alex_Minnaar_Word2Vec_Tutorial_Part_I_The_Skip-Gram_Model.pdf)，[Word2Vec Tutorial Part 2 - Negative Sampling](http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/)

- [word2vec Explained: Deriving Mikolov et al.’s Negative-Sampling Word-Embedding Method](https://arxiv.org/pdf/1402.3722.pdf)

- [word2vec Parameter Learning Explained](https://arxiv.org/pdf/1411.2738.pdf)

- [论文翻译章节：基于 Negative Sampling 的模型 ](http://blog.csdn.net/itplus/article/details/37998797)

- [word2vec: negative sampling (in layman term)?](http://stackoverflow.com/questions/27860652/word2vec-negative-sampling-in-layman-term)

- [Deep-Learning-What-is-meant-by-a-distributed-representation](https://www.quora.com/Deep-Learning/Deep-Learning-What-is-meant-by-a-distributed-representation)

- [Google - Word2Vec](https://code.google.com/p/word2vec/)

- [Deep Learning 实战之 word2vec](http://techblog.youdao.com/?p=915#LinkTarget_699)

- [word2vector 学习笔记(一)](http://blog.csdn.net/lingerlanlan/article/details/38048335)

- [词向量和语言模型](http://licstar.net/archives/328#s20)

- [关于多个词向量算法的实现对比](https://github.com/licstar/compare)

- [斯坦福深度学习课程第二弹：词向量内部和外部任务评价](https://zhuanlan.zhihu.com/p/21391710)
