# 3D Generation

- [2023~Awesome-Text-to-3D ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/yyeboah/Awesome-Text-to-3D)](https://github.com/yyeboah/Awesome-Text-to-3D): A growing curation of Text-to-3D, Diffusion-to-3D works. Heavily inspired by awesome-NeRF.

# OpenSource

## Image & Text To Mesh

- [2018~mlivesu/slice2mesh ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/mlivesu/slice2mesh)](https://github.com/mlivesu/slice2mesh): a Meshing Tool for the Simulation of Additive Manufacturing Processes

- [2018~ThibaultGROUEIX/AtlasNet ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/ThibaultGROUEIX/AtlasNet)](https://github.com/ThibaultGROUEIX/AtlasNet): This repository contains the source codes for the paper "AtlasNet: A Papier-Mâché Approach to Learning 3D Surface Generation ". The network is able to synthesize a mesh (point cloud + connectivity) from a low-resolution point cloud, or from an image.

- [2018~Pix3d ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/xingyuansun/pix3d)](https://github.com/xingyuansun/pix3d): Dataset and Methods for Single-Image 3D Shape Modeling.

- [2019~Pixel2Mesh ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/nywang16/Pixel2Mesh)](https://github.com/nywang16/Pixel2Mesh): Generating 3D Mesh Models from Single RGB Images. In ECCV2018.

- [2021~AOT-AG/DicomToMesh ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/AOT-AG/DicomToMesh)](https://github.com/AOT-AG/DicomToMesh): A command line tool to transform a DICOM volume into a 3d surface mesh (obj, stl or ply). Several mesh processing routines can be enabled, such as mesh reduction, smoothing or cleaning. Works on Linux, OSX and Windows.

- [2021~text2mesh ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/threedle/text2mesh)](https://github.com/threedle/text2mesh): 3D mesh stylization driven by a text input in PyTorch.

- [2022~Point·E ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/openai/point-e)](https://github.com/openai/point-e): Point cloud diffusion for 3D model synthesis

- [2022~stable-dreamfusion ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/ashawkey/stable-dreamfusion)](https://github.com/ashawkey/stable-dreamfusion): A pytorch implementation of text-to-3D dreamfusion, powered by stable diffusion.

- [2023~pix2pix3D ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/dunbar12138/pix2pix3D)](https://github.com/dunbar12138/pix2pix3D): This is the official PyTorch implementation of "3D-aware Conditional Image Synthesis". Pix2pix3D synthesizes 3D objects (neural fields) given a 2D label map, such as a segmentation or edge map. We also provide an interactive 3D editing demo.

- [2023~zero123 ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/cvlab-columbia/zero123)](https://github.com/cvlab-columbia/zero123): We learn to control the camera perspective in large-scale diffusion models, enabling zero-shot novel view synthesis and 3D reconstruction from a single image.

- [2023~guochengqian/Magic123 ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/guochengqian/Magic123)](https://github.com/guochengqian/Magic123): One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors.

- [2023~DreamGaussian ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/dreamgaussian/dreamgaussian)](https://github.com/dreamgaussian/dreamgaussian): Generative Gaussian Splatting for Efficient 3D Content Creation.

- [2023~GaussianDreamer ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/hustvl/GaussianDreamer)](https://github.com/hustvl/GaussianDreamer): Fast Generation from Text to 3D Gaussian Splatting with Point Cloud Priors.

- [2023~Shap-E ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/openai/shap-e)](https://github.com/openai/shap-e): Generate 3D objects conditioned on text or images.

  - [kedzkiest/shap-e-local ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/kedzkiest/shap-e-local)](https://github.com/kedzkiest/shap-e-local): The code to run shap-e text-to-3d sample code locally.

- [HeadSculpt ![code](https://ng-tech.icu/assets/code.svg)](https://brandonhan.uk/HeadSculpt/): HeadSculpt can create an assortment of head avatars, including humans (both celebrities and ordinary individuals) as well as non-human characters like superheroes, comic/game characters, paintings, and more.

- [2023~Gorilla-Lab-SCUT/Fantasia3D ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/Gorilla-Lab-SCUT/Fantasia3D)](https://github.com/Gorilla-Lab-SCUT/Fantasia3D): Disentangling Geometry and Appearance for High-quality Text-to-3D Content Creation.

- [2023~DreamCraft3D ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/deepseek-ai/DreamCraft3D)](https://github.com/deepseek-ai/DreamCraft3D): Official implementation of DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion Prior

- [2023~One-2-3-45 ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/One-2-3-45/One-2-3-45)](https://github.com/One-2-3-45/One-2-3-45): One-2-3-45 rethinks how to leverage 2D diffusion models for 3D AIGC and introduces a novel forward-only paradigm that avoids time-consuming optimization.

- [2023~TripoSR ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/VAST-AI-Research/TripoSR)](https://github.com/VAST-AI-Research/TripoSR): This is the official codebase for TripoSR, a state-of-the-art open-source model for fast feedforward 3D reconstruction from a single image, collaboratively developed by Tripo AI and Stability AI.

- [2024~Era3D ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/pengHTYX/Era3D)](https://github.com/pengHTYX/Era3D): High-Resolution Multiview Diffusion using Efficient Row-wise Attention.

- [2024~Unique3D ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/AiuniAI/Unique3D)](https://github.com/AiuniAI/Unique3D): Official implementation of Unique3D: High-Quality and Efficient 3D Mesh Generation from a Single Image.

- [2024~Stability-AI/stable-fast-3d ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/Stability-AI/stable-fast-3d)](https://github.com/Stability-AI/stable-fast-3d): Stable Fast 3D Mesh Reconstruction with UV-unwrapping and Illumination Disentanglement.

## Human Head Reconstruction

- [SizheAn/PanoHead ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/SizheAn/PanoHead)](https://github.com/SizheAn/PanoHead): Code Repository for CVPR 2023 Paper "PanoHead: Geometry-Aware 3D Full-Head Synthesis in 360 degree"

## Multiple View

- [2023~SUDO-AI-3D/zero123plus ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/SUDO-AI-3D/zero123plus)](https://github.com/SUDO-AI-3D/zero123plus): a Single Image to Consistent Multi-view Diffusion Base Model.

## 3D Modeling

- [2023~Chuny1/3DGPT ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/Chuny1/3DGPT)](https://github.com/Chuny1/3DGPT): 3D-GPT employs LLMs as a multi-agent system with three collaborative agents for procedural 3D generation.
