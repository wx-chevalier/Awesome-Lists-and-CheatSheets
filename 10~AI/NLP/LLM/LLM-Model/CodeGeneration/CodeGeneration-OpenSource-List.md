# Code Generation OpenSource List

- [2022~CodeGeeX ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/THUDM/CodeGeeX)](https://github.com/THUDM/CodeGeeX): We introduce CodeGeeX, a large-scale multilingual code generation model with 13 billion parameters, pre-trained on a large code corpus of more than 20 programming languages. As of June 22, 2022, CodeGeeX has been trained on more than 850 billion tokens on a cluster of 1,536 Ascend 910 AI Processors.

- [2023~Tabby ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/TabbyML/tabby)](https://github.com/TabbyML/tabby): Self-hosted AI coding assistant. An opensource / on-prem alternative to GitHub Copilot.

- [2023~Turbopilot ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/ravenscroftj/turbopilot)](https://github.com/ravenscroftj/turbopilot): Turbopilot is an open source large-language-model based code completion engine that runs locally on CPU

- [2023~GPT-Code-Clippy ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/CodedotAl/gpt-code-clippy)](https://github.com/CodedotAl/gpt-code-clippy): GPT-Code-Clippy (GPT-CC) is an open source version of GitHub Copilot, a language model -- based on GPT-3, called GPT-Codex -- that is fine-tuned on publicly available code from GitHub.

- [2023~ReactAgent ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/eylonmiz/react-agent)](https://github.com/eylonmiz/react-agent): ReactAgent is an experimental autonomous agent that uses GPT-4 language model to generate and compose React components from user stories. It is built with React, TailwindCSS, Typescript, Radix UI, Shandcn UI, and OpenAI API.

- [2023~Magicoder ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/ise-uiuc/magicoder)](https://github.com/ise-uiuc/magicoder): ðŸŽ©Magicoder is a model family empowered by ðŸª„OSS-Instruct, a novel approach to enlightening LLMs with open-source code snippets for generating low-bias and high-quality instruction data for code.
