# Awesome 3D CV List

- [2018-An Invitation to 3D Vision: A Tutorial for Everyone üóÉÔ∏è](https://github.com/mint-lab/3dv_tutorial): An Invitation to 3D Vision is an introductory tutorial on 3D vision (a.k.a. geometric vision or visual geometry or multi-view geometry). It aims to make beginners understand basic theory of 3D vision and implement their own applications using OpenCV. In addition to tutorial slides, example codes are provided in the purpose of education. They include simple but interesting and practical applications. The example codes are written as short as possible (mostly less than 100 lines) to be clear and easy to understand.

- [2022-DiffusionNet ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/nmwsharp/diffusion-net)](https://github.com/nmwsharp/diffusion-net): DiffusionNet is a general-purpose method for deep learning on surfaces such as 3D triangle meshes and point clouds. It is well-suited for tasks like segmentation, classification, feature extraction, etc.

# Classification

- [2016-Pointnet ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/charlesq34/pointnet)](https://github.com/charlesq34/pointnet): Deep Learning on Point Sets for 3D Classification and Segmentation.

# Mesh Generation

## Image To Mesh

- [2018-mlivesu/slice2mesh ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/mlivesu/slice2mesh)](https://github.com/mlivesu/slice2mesh): a Meshing Tool for the Simulation of Additive Manufacturing Processes

- [2018-ThibaultGROUEIX/AtlasNet ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/ThibaultGROUEIX/AtlasNet)](https://github.com/ThibaultGROUEIX/AtlasNet): This repository contains the source codes for the paper "AtlasNet: A Papier-M√¢ch√© Approach to Learning 3D Surface Generation ". The network is able to synthesize a mesh (point cloud + connectivity) from a low-resolution point cloud, or from an image.

- [2018-Pix3d ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/xingyuansun/pix3d)](https://github.com/xingyuansun/pix3d): Dataset and Methods for Single-Image 3D Shape Modeling.

- [2019-Pixel2Mesh ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/nywang16/Pixel2Mesh)](https://github.com/nywang16/Pixel2Mesh): Generating 3D Mesh Models from Single RGB Images. In ECCV2018.

- [2021-AOT-AG/DicomToMesh ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/AOT-AG/DicomToMesh)](https://github.com/AOT-AG/DicomToMesh): A command line tool to transform a DICOM volume into a 3d surface mesh (obj, stl or ply). Several mesh processing routines can be enabled, such as mesh reduction, smoothing or cleaning. Works on Linux, OSX and Windows.

- [2022-stable-dreamfusion ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/ashawkey/stable-dreamfusion)](https://github.com/ashawkey/stable-dreamfusion): A pytorch implementation of text-to-3D dreamfusion, powered by stable diffusion.

- [2023-pix2pix3D ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/dunbar12138/pix2pix3D)](https://github.com/dunbar12138/pix2pix3D): This is the official PyTorch implementation of "3D-aware Conditional Image Synthesis". Pix2pix3D synthesizes 3D objects (neural fields) given a 2D label map, such as a segmentation or edge map. We also provide an interactive 3D editing demo.

- [2023-zero123 ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/cvlab-columbia/zero123)](https://github.com/cvlab-columbia/zero123): We learn to control the camera perspective in large-scale diffusion models, enabling zero-shot novel view synthesis and 3D reconstruction from a single image.

## Text To Mesh

- [2021-text2mesh ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/threedle/text2mesh)](https://github.com/threedle/text2mesh): 3D mesh stylization driven by a text input in PyTorch.

- [2022-Point¬∑E ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/openai/point-e)](https://github.com/openai/point-e): Point cloud diffusion for 3D model synthesis

- [2023-Shap-E ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/openai/shap-e)](https://github.com/openai/shap-e): Generate 3D objects conditioned on text or images.
