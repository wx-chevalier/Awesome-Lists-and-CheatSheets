# Crawler OpenSource List | 爬虫开源框架索引

# Platform

- [2019-SpiderFlow ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/ssssssss-team/spider-flow)](https://github.com/ssssssss-team/spider-flow): 新一代爬虫平台，以图形化方式定义爬虫流程，不写代码即可完成爬虫。

- [2020-Crawlab ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/crawlab-team/crawlab)](https://github.com/crawlab-team/crawlab): Distributed web crawler admin platform for spiders management regardless of languages and frameworks.

# Framework

## Node

- [x-ray ![code](https://ng-tech.icu/assets/code.svg)](https://github.com/lapwinglabs/x-ray): The next web scraper. See through the <html> noise.

- [headless-chrome-crawler ![code](https://ng-tech.icu/assets/code.svg)](https://github.com/yujiosaka/headless-chrome-crawler): Distributed crawler powered by Headless Chrome.

- [apify-js ![code](https://ng-tech.icu/assets/code.svg)](https://github.com/apify/apify-js): Apify SDK — The scalable web scraping and crawling library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.

- [2021-Crawlee ![code](https://ng-tech.icu/assets/code.svg)](https://github.com/apify/crawlee): A web scraping and browser automation library for Node.js that helps you build reliable crawlers. Fast.

## Python

- [2018-Scrapy ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/scrapy/scrapy)](https://github.com/scrapy/scrapy): Scrapy is a fast high-level web crawling and web scraping framework, used to crawl websites and extract structured data from their pages. It can be used for a wide range of purposes, from data mining to monitoring and automated testing.

- [2019-pyspider ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/binux/pyspider)](https://github.com/binux/pyspider): A Powerful Spider(Web Crawler) System in Python.

- [Photon ![code](https://ng-tech.icu/assets/code.svg)](https://github.com/s0md3v/Photon): Incredibly fast crawler which extracts urls, emails, files, website accounts and much more.

- [Gerapy ![code](https://ng-tech.icu/assets/code.svg)](https://github.com/Gerapy/Gerapy): Distributed Crawler Management Framework Based on Scrapy, Scrapyd, Scrapyd-Client, Scrapyd-API, Django and Vue.js.

## Golang

- [2015-go_spider ![code](https://ng-tech.icu/assets/code.svg)](https://github.com/hu17889/go_spider): An awesome Go concurrent Crawler(spider) framework. The crawler is flexible and modular. It can be expanded to an Individualized crawler easily or you can use the default crawl components only.

- [2017-Colly ![code](https://ng-tech.icu/assets/code.svg)](https://github.com/gocolly/colly): Lightning Fast and Elegant Scraping Framework for Gophers.

- [2018-ferret ![code](https://ng-tech.icu/assets/code.svg)](https://github.com/MontFerret/ferret): ferret is a web scraping system aiming to simplify data extraction from the web for such things like UI testing, machine learning and analytics.

- [2019-Hakrawler ![code](https://ng-tech.icu/assets/code.svg)](https://github.com/hakluke/hakrawler): Simple, fast web crawler designed for easy, quick discovery of endpoints and assets within a web application.

- [2022-katana ![code](https://ng-tech.icu/assets/code.svg)](https://github.com/projectdiscovery/katana): A next-generation crawling and spidering framework.

## Java

- [Crawler4j ![code](https://ng-tech.icu/assets/code.svg)](https://github.com/yasserg/crawler4j): crawler4j is an open source web crawler for Java which provides a simple interface for crawling the Web. Using it, you can setup a multi-threaded web crawler in few minutes.

- [2015-WebMagic ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/code4craft/webmagic)](https://github.com/code4craft/webmagic): A scalable crawler framework. It covers the whole lifecycle of crawler: downloading, url management, content extraction and persistent. It can simplify the development of a specific crawler.

# Content Analysis | 内容分析

- [Fathom ![code](https://ng-tech.icu/assets/code.svg)](https://github.com/mozilla/fathom): A framework for extracting meaning from web pages.

- [unicaps ![code](https://ng-tech.icu/assets/code.svg)](https://github.com/sergey-scat/unicaps): A unified Python API for CAPTCHA solving services.

# Visual Config

- [2023-EasySpider ![code](https://ng-tech.icu/assets/code.svg) ![star](https://img.shields.io/github/stars/NaiboWang/EasySpider)](https://github.com/NaiboWang/EasySpider): A visual no-code/code-free web crawler/spider 一个可视化爬虫软件，可以无代码图形化设计和执行的爬虫任务
